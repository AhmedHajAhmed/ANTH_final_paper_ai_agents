# Decolonial AI Conversations

This project explores how large language models (LLMs) reflect and reproduce epistemological biases, particularly those rooted in Western mainstream knowledge traditions. By designing two distinct AI agents‚Äîone grounded in Western epistemology and the other in Decolonial epistemology‚Äîwe simulate and analyze conversations on topics related to knowledge, culture, and power.

## üß† Project Summary

- **Goal:** Investigate how epistemological assumptions influence AI-generated discourse.
- **Method:** Simulate multi-turn conversations between two agents with distinct epistemological frameworks.
- **Topics Explored:**
  - What counts as valid knowledge in different cultural contexts?
  - How do we define progress across cultures?
  - Leadership and power in different traditions
  - Integrating traditional and scientific knowledge
  - Technology and cultural values

## üõ†Ô∏è Technical Overview

- **Model:** OpenAI GPT-4 via API
- **Agents:**
  - `Western Mainstream Agent`: prioritizes empiricism, universality, objectivity
  - `Decolonial Agent`: prioritizes context, community knowledge, power analysis
- **Temperature Settings:**
  - Response generation: `temperature=0.7`
  - Assumption & power analysis: `temperature=0.3`
- **Output:** JSON files capturing full dialogue turns, assumptions, and power dynamics


## üîó Related Work

- Ruha Benjamin, *Race After Technology*
- Linda Tuhiwai Smith, *Decolonizing Methodologies*
- Haraway, *Situated Knowledges*
- Tuck & Yang, *Decolonization is Not a Metaphor*

